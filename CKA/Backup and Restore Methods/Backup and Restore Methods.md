<img src="image.png" width="600" height="200"><br>

При создании объектов в кластере мы можем использовать как императивный, так и декларативный подходы. Если вы хотите сохранить свою конфигурацию, более предпочтительным является декларативный подход. Хорошей практикой является хранение object definition файлов в репозитории. Репозиторий в свою очередь должен бекапироваться.

Но, не смотря на то, что декларативный подход является предпочтительным, это вовсе не означает, что все члены вашей команды будут его придерживаться. Что если кто-то из коллег создаст объект императивным способом без документирования этой информации где-либо?

Более подходящий способ для бекапирования конфигурации ресурсов - использовать запрос к apiserver с помощью утилиты kubectl или прямым вызовом API.

Сохранить конфигурацию всех Deployments, Services и Pods во всех namespace: `kubectl get all --all-namespaces -o yaml > all-deploy-services.yaml`.

И это только для некоторых resource groups. Существует множество других resource groups, которые должны учитываться. Для существует инструмент *Velero*.

Перейдем к etcd. Etcd хранит информацию о состоянии нашего кластера, его нод, каждого ресурса созданного в нем. Вместо бекапирования ресурсов описанного в предыдущем подходе, вы можете выбрать бекапирование самого etcd-сервера.

Etcd-кластер располагается на master-нодах. При конфигурировании etcd мы указываем путь, где будут храниться все данные. Эта директория может быть настроена для бекапа с помощью вашего инструмента бекапирования.

<img src="image-1.png" width="400" height="300"><br>

Также у etcd есть встроенное решения для создания snapshot-ов.

Создать snapshot БД etcd: `ETCDCTL_API=3 etcdctl snapshot save snapshot.db`. Файл `snapshot.db` будет создан в текущей директории. Если нужно создать файл в другом каталоге, укажите полный путь.

Посмотреть статус бекапа: `ETCDCTL_API=3 etcdctl snapshot status snapshot.db`.

Для восстановление кластера из бекапа сначала нужно остановить kube-apiserver: `service kube-apiserver stop`, т.к. процесс восстановления потребует рестарта etcd-кластера, а kube-apiserver зависит от него.

Затем выполняем команду: `ETCDCTL_API=3 etcdctl snapshot restore snapshot.db --data-dir=/var/lib/etcd-from-backup`.

Когда etcd восстанавливается из бекапа, он инициализирует новую конфигурацию кластера и настраивает членов etcd как новых членов нового кластера. Это сделано для предотвращения случайного присоединения нового участника к существующему кластеру. При запуске данной команды будет создана новая data directory `/var/lib/etcd-from-backup`.

Затем мы настраиваем конфигурацию etcd для использования новой data directory.

<img src="image-2.png" width="400" height="300"><br>

Затем перезапускаем сервис etcd:

```bash
systemctl daemon-reload
service etcd restart
```

И в конце запускаем kube-apiserver: `service kube-apiserver start`. После этого кластер должен вернуться в исходное состояние.

Для всех etcd-команд нужно указывать файлы сертификатов для аутентификации, endpoint для etcd-кластера и ключ.

```bash
ETCDCTL_API=3 etcdctl \
  snapshot save snapshot.db \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/etcd/ca.crt \
  --cert=/etc/etcd/etcd-server.crt \
  --key=/etc/etcd/etcd-server.key
```

Если вы используете managed K8s окружение, то у вас может не быть доступа к etcd-кластеру. В этом случае бэкап с помощью запроса к kube-apiserver возможно будет более подходящим решением.