Предположим, мы разрабатываем приложения для онлайн-магазина и оно будет доступно по адресу www.my-online-store.com

Мы упаковали приложение (wear) в Docker-образ и развернули в K8s как часть Deployment

Также для приложения потребуется pod с БД MySQL и Service типа ClusterIP под названием mysql-service, чтобы сделать БД доступной для нашего приложения

Чтобы сделать приложение доступным извне, мы создаем другой тип Service - NodePort под названием wear-service, публикация на порт 38080 на нодах кластера

Теперь пользователи могут получить доступ к приложению по `http://<node-ip:38080>`

Если увеличится нагрузка на приложение, мы можем просто увеличить количество pod-ов в ReplicaSet, а Service позабодится о разделении трафика между pod-ами

<img src="screenshot.png" width="700" height="300"><br>

В production environment пользователь не захочет каждый раз вводить ip-адрес, поэтому мы настроим DNS, чтобы ссылаться на ip-адрес ноды кластера

Теперь пользователи смогут получить доступ к приложению по ссылке http://my-online-store.com:38080

Однако мы не хотим, чтобы пользователь также указывал номер порта, тем более такое большое значение

Для этого мы поставим перед нашим кластером proxy-сервер, который будет проксировать запросы с порта 80 на порт 38080

Теперь мы настроим DNS, чтобы ссылаться на ip-адрес proxy-сервера и пользователи смогут получить доступ к приложению по ссылке http://my-online-store.com

<img src="proxy.png" width="300" height="300"><br>

Это был сценарий размещения кластера On-Premise в дата-центре, теперь вернемся немного назад и рассмотрим вариант размещения в Google Cloud Platform

Вместо создания Service типа NodePort, мы создадим другой тип Service - LoadBalancer

После этого K8s сделает все тоже самое - выставит порт 38080 на ноде, но в дополнение пошлет запрос в GCP на создание балансировщика нагрузки

После получения запроса GCP автоматически создаст балансировщик, настроенный для маршрутизации трафик на порт Service на всех нодах кластера и вернет эту информацию в K8s

Балансировщик имеет внешний ip, мы настроим DNS, чтобы ссылаться на этот ip-адрес и в результате пользователи смогут получить доступ к приложению по ссылке http://my-online-store.com

<img src="gcp-lb.png" width="400" height="300"><br>

Наш бизнес растет - мы хотим запустить новый стриминговый сервис и чтобы он был доступен по адресу www.my-online-store.com/watch, а старое приложение теперь будет доступно по адресу www.my-online-store.com/wear

Мы развернули новый Deployment для стримингового приложения в том же кластере, создали Service типа LoadBalancer под названием video-service, K8s выставил порт 38282 для Service, а также автоматически создался балансировщик нагрузки в GCP

Новый балансировщик имеет отдельный внешний ip и важно помнить, что мы платим деньги за каждый из балансировщиков, соответственно если у нас будет много LB - это сильно увеличит наш ежемесячный платеж за услуги Cloud-провайдера

Как мы будем направлять трафик на каждый из этих LB в зависимости от введенной пользователем ссылки?

Нам нужен отдельный Proxy или LoadBalancer, который будет перенаправлять трафик в зависимости от введенной пользователем ссылки

Соответственно каждый раз, когда мы будет добавлять новый сервис (приложение), мы должны будем переконфигурировать этот вышестоящий Proxy/LB

Кроме того нам нужен SSL, чтобы пользователи входили по ссылке https://my-online-store.com

Где нужно настроить SSL? Это можно сделать на разных уровнях - в самом приложении, на proxy-сервере или на балансировщике

Мы не хотим просить разработчиков настраивать SSL в приложении, т.к. разные команды сделают это по разному, мы хотим настроить SSL в одном месте с минимальным дальнейшим обслуживанием

<img src="gcp-lb2.png" width="500" height="300"><br>

Настройка потребует много усилий и управлять этим станет еще сложнее, когда приложение будет масштабироваться, потребуются специалисты из разных команд для настройки, нужно будет настраивать правила на firewall для каждого нового сервиса (приложения), и это будет дорого, т.к. каждый раз нужно будет создавать LoadBalancer у cloud-провайдера

Было бы здорово управлять всем этим процессом непосредственно в кластере K8s и сделать всю конфигурацию просто в формате еще одного YAML-файла, который хранится вместе с остальными файлами для деплоя приложения

И здесь нам поможет Ingress!

Ingress дает возможность получить доступ к приложению, используя единый доступный извне URL, и мы можем настроить маршрутизацию к разным Services в кластере, основываясь на URL path, а также настроить SSL

Ingree стоит рассматировать как L7 балансировщик нагрузки, встроенный в K8s кластер, который может быть настроен как еще один объект K8s

Важно понимать, что мы должны сделать Ingress доступным извне кластера, то есть опубликовать как NodePort или cloud-native LoadBalancer